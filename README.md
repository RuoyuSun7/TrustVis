# TrustVis

TrustVis is an evaluation and visualization toolkit for assessing large language model (LLM) trustworthiness across safety, robustness, and hallucination dimensions. It couples a Next.js dashboard with Python pipelines that consolidate benchmark runs into interactive reports.

By Momentum Lab@UA

## Highlights
- Next.js App Router UI styled with MUI + Tailwind for browsing datasets, models, test executions, and report cards.
- Safety, robustness, and hallucination views powered by reusable chart/table components that read from JSON artefacts in `data_ui/`.
- Python extraction and evaluator scripts that merge raw benchmarks, run Longformer and Llama Guard variants, and emit JSON for the frontend.
- Jupyter notebooks and helper utilities for deeper analysis or for adapting the pipeline to new models and datasets.

## Repository Layout
```text
.
├── app/             # Next.js routes, layouts, and UI components
├── core/            # Python entry points for preparing merged datasets
├── data_ui/         # Frontend-ready JSON and docs for each report dimension
├── dataset/         # Raw benchmark inputs (safety, robustness, hallucination)
├── dataset_out/     # Outputs generated by the evaluator scripts
├── evaluators/      # Longformer, Llama Guard, Perspective evaluators + orchestrator
├── llm/             # Lightweight clients for external LLM APIs
├── notebook/        # Jupyter notebooks used during exploration and validation
├── public/          # Static assets served by Next.js
├── utils/           # Shared Python helpers for metrics and HTML report generation
└── package.json     # Frontend dependencies and scripts
```

## Getting Started

### Prerequisites
- Node.js 18+ (Next.js 15 requires a current LTS runtime)
- npm (bundled with Node.js) or another package manager
- Python 3.10+ with `pip` for the data-processing utilities

### Install and run the frontend
```bash
npm install
npm run dev
```

The development server defaults to `http://localhost:3000`. Additional scripts:

- `npm run build` – production build of the Next.js app
- `npm run start` – run the production build
- `npm run lint` – lint TypeScript/JavaScript sources

### Python environment

The Python tools rely on packages such as `pandas`, `numpy`, `tqdm`, `jinja2`, `matplotlib`, `seaborn`, `scikit-learn`, `scipy`, and `pyyaml`. Create a virtual environment and install the dependencies you need, for example:

```bash
python -m venv .venv
source .venv/bin/activate
pip install pandas numpy tqdm jinja2 matplotlib seaborn scikit-learn scipy pyyaml
```

## Processing New Evaluations

Use the following workflow when ingesting a new model or dataset:

1. **Stage raw data** in `dataset/`, following the existing subfolder structure (`safety`, `Robustness`, `Halucination`, etc.).
2. **Merge and clean inputs** with the helpers in `core/data_extraction.py`. Functions like `extract_safety`, `extract_robustness`, and `extract_hallucination` consolidate heterogeneous sources into the `dataset/.../Merged/` folders.
3. **Run automated evaluators** via `evaluators/evaluate.py`. This script calls Longformer and Llama Guard models (v1 and v2) and writes labelled results into `dataset_out/`.
4. **Transform outputs for the UI** using `data_ui/extract.py`. The `SafetyExtraction` and `RobustnessExtraction` classes compute aggregate statistics (confusion matrices, unsafe ratios, taxonomy breakdowns) and emit the JSON files consumed by the React components.
5. **Refresh the dashboard** by copying the generated JSON artefacts into the relevant subdirectory under `data_ui/` (see `data_ui/README.md` for exact filenames and purposes).

Notebooks in `notebook/` mirror the scripted pipeline and provide interactive examples of the analysis steps.

## Frontend Data Sources

- Report tabs (`/reports/[id]`) load chart data from the JSON files in `data_ui/safety`, `data_ui/robustness`, and `data_ui/hallucination`.
- Management views (`/models`, `/tests`, `/datasets`, `/instances/[id]`) rely on data-access helpers under `app/lib/` (implement or adapt these functions to connect to your backend or stub data during development).
- UI primitives live in `app/ui/` and mix Tailwind utility classes with MUI components for layout consistency.

## Integrating LLM or Backend Services

Python modules under `llm/` demonstrate how to talk to providers such as OpenAI, Anthropic, or local LLaMA APIs. The evaluator pipeline expects access to these services when generating new annotations, so configure the relevant API keys or endpoints before running large batches.

## Credits

TrustVis is developed and maintained by Momentum Lab. Please reach out to the team for collaboration opportunities or if you plan to extend the platform to new evaluation dimensions.

<!-- ## Citation

If TrustVis supports your research or product work, please cite Momentum Lab:
 -->


## License

This project is released under the [GNU GPL v3.0](LICENSE).
